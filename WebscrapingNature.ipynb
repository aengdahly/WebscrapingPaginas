{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WebscrapingNature.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aengdahly/WebscrapingPaginas/blob/main/WebscrapingNature.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-jKPd4w43U-"
      },
      "source": [
        "# Webscraping para Revista Nature."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_-xw6H95WI9"
      },
      "source": [
        "## Paquetes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPcqEIhn42C5"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import os\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ESmWaoJ58UU"
      },
      "source": [
        "## Completar la frase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6P9I0Ahq5UsD"
      },
      "source": [
        "frase='marine litter'\n",
        "url_base='https://www.nature.com/search?q={}&order=relevance&article_type=research'.format(frase)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYZIc6Ys5TZr"
      },
      "source": [
        "page= requests.get(url_base, verify=False)\n",
        "html = BeautifulSoup(page.content, 'html')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGV1aaKuTlnM"
      },
      "source": [
        "## Funciones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALQyzLuUTohm"
      },
      "source": [
        "def EliminarSaltosLinea(oracion):\n",
        "    string = regex.sub(r'[\\n\\r\\t\\xa0\\xad]',' ', oracion)\n",
        "    return(''.join(c for c in string))\n",
        "\n",
        "def EliminarEspaciosExtras(oracion):\n",
        "    string = regex.sub(r'\\s{2,}',' ', oracion)\n",
        "    return(''.join(c for c in string))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7IIdsUsGXvW"
      },
      "source": [
        "## Obtener la última página."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeoEG4df7RIm"
      },
      "source": [
        "paginacion=html.findAll('li',{'class': 'inline-group-item inline-group-middle'})\n",
        "ult_page=int(paginacion[-2].text.replace('\\n\\npage',''))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "Rly51NcH8rHn",
        "outputId": "350ec7cd-a50c-4a41-d9c3-f7995eb27ca1"
      },
      "source": [
        "datos = pd.DataFrame(columns=['Titulo','Pagina','Abstract','Archivo'])\n",
        "\n",
        "for i in range(1,ult_page+1) : #\n",
        "    # por cada pàgina\n",
        "    if i==1:\n",
        "        url=url_base\n",
        "    else:\n",
        "        url=url_base+'&page={}'.format(i)\n",
        "\n",
        "    page= requests.get(url, verify=False)\n",
        "    html = BeautifulSoup(page.content, 'html')\n",
        "    titulos=html.findAll('h2',{'class': 'h3 extra-tight-line-height'})\n",
        "    links=[z.find('a',{'href': True})['href'] for z in titulos]\n",
        "  \n",
        "\n",
        "    for j in links:\n",
        "      direccion='https://www.nature.com{}'.format(j)\n",
        "      pagina_articulo=requests.get(direccion, verify=False)\n",
        "      html2= BeautifulSoup(pagina_articulo.content, 'html')\n",
        "\n",
        "      titulo=html2.find('h1',{'class':'c-article-title'}).text\n",
        "      p=html2.find('div',{'class':'c-article-section__content','id':'Abs1-content'})\n",
        "      if (p!=None):\n",
        "        abstract=EliminarEspaciosExtras(EliminarSaltosLinea(p.text))\n",
        "      else:\n",
        "        abstract='No tiene Abstract como html'  \n",
        "      archivo=direccion+'.pdf'\n",
        "      datos = datos.append({'Titulo':titulo,'Pagina':direccion,'Abstract':abstract,'Archivo': archivo}, ignore_index=True)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-abeca221bf36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhtml2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'div'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'c-article-section__content'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'Abs1-content'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mabstract\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEliminarEspaciosExtras\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEliminarSaltosLinea\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mabstract\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'No tiene Abstract como html'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-4319b02f91e2>\u001b[0m in \u001b[0;36mEliminarSaltosLinea\u001b[0;34m(oracion)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mEliminarSaltosLinea\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moracion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mstring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'[\\n\\r\\t\\xa0\\xad]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moracion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mEliminarEspaciosExtras\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moracion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'regex' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgrIdVE3KK-5"
      },
      "source": [
        "## Guardar archivo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWwy3ictI0Gz"
      },
      "source": [
        "datos.to_csv(frase+'.csv',index=False, sep='|')\n",
        "files.download(frase+'.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}